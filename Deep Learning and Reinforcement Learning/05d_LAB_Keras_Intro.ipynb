{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "_fwV46HiIyCY"
      },
      "source": [
        "# Machine Learning Foundation\n",
        "\n",
        "## Course 5, Part d: Keras Intro LAB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqt6ArqJIyCf"
      },
      "source": [
        "## Using Keras to Build and Train Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp2tD5G4IyCh"
      },
      "source": [
        "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
        "\n",
        "## UCI Pima Diabetes Dataset\n",
        "\n",
        "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
        "\n",
        "\n",
        "### Attributes: (all numeric-valued)\n",
        "   1. Number of times pregnant\n",
        "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "   3. Diastolic blood pressure (mm Hg)\n",
        "   4. Triceps skin fold thickness (mm)\n",
        "   5. 2-Hour serum insulin (mu U/ml)\n",
        "   6. Body mass index (weight in kg/(height in m)^2)\n",
        "   7. Diabetes pedigree function\n",
        "   8. Age (years)\n",
        "   9. Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Is_NBGDIyCl"
      },
      "source": [
        "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mGu3q9GlIyCo"
      },
      "outputs": [],
      "source": [
        "#Setup\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q3zHhzD1IyCr"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "#from keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TzbwRT5eIyCu"
      },
      "outputs": [],
      "source": [
        "## Load in the data set \n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv('/content/diabetes.csv', names=names, header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RAQNKBTBIyCw",
        "outputId": "9506fcbf-23b2-419c-af48-b5d871ffa367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "641               4                     128              70               0   \n",
              "370               3                     173              82              48   \n",
              "740              11                     120              80              37   \n",
              "410               6                     102              90              39   \n",
              "299               8                     112              72               0   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "641        0  34.3              0.303   24             0  \n",
              "370      465  38.4              2.137   25             1  \n",
              "740      150  42.3              0.785   48             1  \n",
              "410        0  35.7              0.674   28             0  \n",
              "299        0  23.6              0.840   58             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0c827eb-bc44-4e00-affc-1d932e18b829\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>641</th>\n",
              "      <td>4</td>\n",
              "      <td>128</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34.3</td>\n",
              "      <td>0.303</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>3</td>\n",
              "      <td>173</td>\n",
              "      <td>82</td>\n",
              "      <td>48</td>\n",
              "      <td>465</td>\n",
              "      <td>38.4</td>\n",
              "      <td>2.137</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>740</th>\n",
              "      <td>11</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>37</td>\n",
              "      <td>150</td>\n",
              "      <td>42.3</td>\n",
              "      <td>0.785</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>6</td>\n",
              "      <td>102</td>\n",
              "      <td>90</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>35.7</td>\n",
              "      <td>0.674</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>8</td>\n",
              "      <td>112</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.6</td>\n",
              "      <td>0.840</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0c827eb-bc44-4e00-affc-1d932e18b829')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0c827eb-bc44-4e00-affc-1d932e18b829 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0c827eb-bc44-4e00-affc-1d932e18b829');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sTgaEBQTIyCx"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d3g0IUBZIyC0"
      },
      "outputs": [],
      "source": [
        "# Split the data to Train, and Test (75%, 25%)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zAunZq8mIyC2",
        "outputId": "4a5cdefc-6ba1-438f-afcc-53608b6dcb15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jAj48lKIyC5"
      },
      "source": [
        "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
        "## Exercise 1: Get a baseline performance using Random Forest\n",
        "To begin, and get a baseline for classifier performance:\n",
        "1. Train a Random Forest model with 200 trees on the training data.\n",
        "2. Calculate the accuracy and roc_auc_score of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5iRT7Yc7IyC5",
        "outputId": "edfc5e6d-85b2-45e9-8d63-59f0efd3e9a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "### BEGIN SOLUTION\n",
        "## Train the RF Model\n",
        "rf_model = RandomForestClassifier(n_estimators=200)\n",
        "rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Vgt9ee_KIyC7",
        "outputId": "7389938d-17c4-4b83-c3f1-2e29bee3f394",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.766\n",
            "roc-auc is 0.832\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
        "y_pred_class_rf = rf_model.predict(X_test)\n",
        "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ubIK7yD_IyC8",
        "outputId": "5019e752-c83b-4037-b9c7-d7b668f77f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myf2LXqVIyC_"
      },
      "source": [
        "## Build a Single Hidden Layer Neural Network\n",
        "\n",
        "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PEYCAmQKIyC_"
      },
      "outputs": [],
      "source": [
        "## First let's normalize the data\n",
        "## This aids the training of neural nets by providing numerical stability\n",
        "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "H0S_7SdGIyDB"
      },
      "outputs": [],
      "source": [
        "# Define the Model \n",
        "# Input size is 8-dimensional\n",
        "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
        "\n",
        "model_1 = Sequential()\n",
        "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
        "model_1.add(Dense(1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vZUk7dndIyDB",
        "outputId": "ffd3dd23-939a-4438-9e8c-d31e0d55115a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#  This is a nice tool to view the model you have created and count the parameters\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7dOzWrTIyDD"
      },
      "source": [
        "### Comprehension question:\n",
        "Why do we have 121 parameters?  Does that make sense?\n",
        "> 9 * 12\n",
        "\n",
        "Let's fit our model for 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bP-Kpa9fIyDE",
        "outputId": "557e702f-5683-42cf-971a-aba43a9cace7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 14ms/step - loss: 0.6864 - accuracy: 0.5729 - val_loss: 0.6866 - val_accuracy: 0.5938\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6818 - accuracy: 0.5816 - val_loss: 0.6826 - val_accuracy: 0.5885\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.6007 - val_loss: 0.6790 - val_accuracy: 0.6146\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.6059 - val_loss: 0.6757 - val_accuracy: 0.6198\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6285 - val_loss: 0.6726 - val_accuracy: 0.6458\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6372 - val_loss: 0.6698 - val_accuracy: 0.6771\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.6545 - val_loss: 0.6672 - val_accuracy: 0.6823\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.6580 - val_loss: 0.6648 - val_accuracy: 0.6771\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6684 - val_loss: 0.6626 - val_accuracy: 0.6667\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6701 - val_loss: 0.6605 - val_accuracy: 0.6719\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.6684 - val_loss: 0.6586 - val_accuracy: 0.6667\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.6632 - val_loss: 0.6568 - val_accuracy: 0.6823\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.6597 - val_loss: 0.6551 - val_accuracy: 0.6823\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6597 - val_loss: 0.6535 - val_accuracy: 0.6719\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.6580 - val_loss: 0.6520 - val_accuracy: 0.6771\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6562 - val_loss: 0.6506 - val_accuracy: 0.6719\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6427 - accuracy: 0.6580 - val_loss: 0.6493 - val_accuracy: 0.6719\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6412 - accuracy: 0.6597 - val_loss: 0.6480 - val_accuracy: 0.6667\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6597 - val_loss: 0.6468 - val_accuracy: 0.6667\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.6615 - val_loss: 0.6456 - val_accuracy: 0.6562\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6372 - accuracy: 0.6597 - val_loss: 0.6445 - val_accuracy: 0.6562\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6615 - val_loss: 0.6434 - val_accuracy: 0.6562\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6615 - val_loss: 0.6424 - val_accuracy: 0.6615\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6336 - accuracy: 0.6597 - val_loss: 0.6413 - val_accuracy: 0.6562\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6325 - accuracy: 0.6580 - val_loss: 0.6404 - val_accuracy: 0.6562\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.6580 - val_loss: 0.6394 - val_accuracy: 0.6562\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6580 - val_loss: 0.6385 - val_accuracy: 0.6562\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.6597 - val_loss: 0.6376 - val_accuracy: 0.6562\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6597 - val_loss: 0.6367 - val_accuracy: 0.6510\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.6597 - val_loss: 0.6358 - val_accuracy: 0.6510\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6580 - val_loss: 0.6350 - val_accuracy: 0.6510\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6580 - val_loss: 0.6342 - val_accuracy: 0.6510\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.6580 - val_loss: 0.6334 - val_accuracy: 0.6458\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6238 - accuracy: 0.6580 - val_loss: 0.6326 - val_accuracy: 0.6458\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6229 - accuracy: 0.6597 - val_loss: 0.6318 - val_accuracy: 0.6458\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.6597 - val_loss: 0.6310 - val_accuracy: 0.6458\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.6597 - val_loss: 0.6302 - val_accuracy: 0.6458\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.6597 - val_loss: 0.6295 - val_accuracy: 0.6458\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6580 - val_loss: 0.6287 - val_accuracy: 0.6458\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.6580 - val_loss: 0.6280 - val_accuracy: 0.6458\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6180 - accuracy: 0.6580 - val_loss: 0.6272 - val_accuracy: 0.6458\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.6580 - val_loss: 0.6265 - val_accuracy: 0.6458\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.6580 - val_loss: 0.6258 - val_accuracy: 0.6458\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.6580 - val_loss: 0.6251 - val_accuracy: 0.6458\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.6580 - val_loss: 0.6244 - val_accuracy: 0.6458\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6580 - val_loss: 0.6237 - val_accuracy: 0.6458\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.6580 - val_loss: 0.6230 - val_accuracy: 0.6458\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6580 - val_loss: 0.6223 - val_accuracy: 0.6458\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6580 - val_loss: 0.6216 - val_accuracy: 0.6458\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.6580 - val_loss: 0.6209 - val_accuracy: 0.6458\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6580 - val_loss: 0.6202 - val_accuracy: 0.6458\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6580 - val_loss: 0.6195 - val_accuracy: 0.6458\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6580 - val_loss: 0.6189 - val_accuracy: 0.6458\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.6597 - val_loss: 0.6182 - val_accuracy: 0.6458\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6597 - val_loss: 0.6175 - val_accuracy: 0.6458\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6597 - val_loss: 0.6169 - val_accuracy: 0.6458\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.6597 - val_loss: 0.6162 - val_accuracy: 0.6458\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.6615 - val_loss: 0.6156 - val_accuracy: 0.6458\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6615 - val_loss: 0.6149 - val_accuracy: 0.6458\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.6615 - val_loss: 0.6143 - val_accuracy: 0.6458\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.6615 - val_loss: 0.6136 - val_accuracy: 0.6458\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.6615 - val_loss: 0.6130 - val_accuracy: 0.6458\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6615 - val_loss: 0.6123 - val_accuracy: 0.6458\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.6615 - val_loss: 0.6117 - val_accuracy: 0.6458\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6013 - accuracy: 0.6632 - val_loss: 0.6111 - val_accuracy: 0.6458\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6632 - val_loss: 0.6104 - val_accuracy: 0.6458\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6632 - val_loss: 0.6098 - val_accuracy: 0.6458\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.6632 - val_loss: 0.6092 - val_accuracy: 0.6458\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.6615 - val_loss: 0.6086 - val_accuracy: 0.6458\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6615 - val_loss: 0.6080 - val_accuracy: 0.6458\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.6615 - val_loss: 0.6073 - val_accuracy: 0.6510\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6597 - val_loss: 0.6067 - val_accuracy: 0.6510\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6615 - val_loss: 0.6061 - val_accuracy: 0.6615\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5957 - accuracy: 0.6632 - val_loss: 0.6055 - val_accuracy: 0.6615\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.6632 - val_loss: 0.6049 - val_accuracy: 0.6615\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5945 - accuracy: 0.6649 - val_loss: 0.6043 - val_accuracy: 0.6615\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6649 - val_loss: 0.6037 - val_accuracy: 0.6615\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.6667 - val_loss: 0.6031 - val_accuracy: 0.6615\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5927 - accuracy: 0.6684 - val_loss: 0.6025 - val_accuracy: 0.6615\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5920 - accuracy: 0.6684 - val_loss: 0.6019 - val_accuracy: 0.6615\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.6684 - val_loss: 0.6013 - val_accuracy: 0.6615\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.6701 - val_loss: 0.6008 - val_accuracy: 0.6615\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6719 - val_loss: 0.6002 - val_accuracy: 0.6615\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.6719 - val_loss: 0.5996 - val_accuracy: 0.6615\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5891 - accuracy: 0.6771 - val_loss: 0.5990 - val_accuracy: 0.6667\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5885 - accuracy: 0.6771 - val_loss: 0.5985 - val_accuracy: 0.6667\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5880 - accuracy: 0.6753 - val_loss: 0.5979 - val_accuracy: 0.6667\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5874 - accuracy: 0.6788 - val_loss: 0.5973 - val_accuracy: 0.6667\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.6788 - val_loss: 0.5967 - val_accuracy: 0.6667\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.6788 - val_loss: 0.5962 - val_accuracy: 0.6667\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5857 - accuracy: 0.6788 - val_loss: 0.5956 - val_accuracy: 0.6719\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.6788 - val_loss: 0.5951 - val_accuracy: 0.6719\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5846 - accuracy: 0.6788 - val_loss: 0.5945 - val_accuracy: 0.6719\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6788 - val_loss: 0.5940 - val_accuracy: 0.6719\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5835 - accuracy: 0.6788 - val_loss: 0.5934 - val_accuracy: 0.6719\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6788 - val_loss: 0.5929 - val_accuracy: 0.6719\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.6788 - val_loss: 0.5923 - val_accuracy: 0.6719\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6788 - val_loss: 0.5918 - val_accuracy: 0.6719\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.6806 - val_loss: 0.5912 - val_accuracy: 0.6771\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.6823 - val_loss: 0.5907 - val_accuracy: 0.6771\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.6823 - val_loss: 0.5902 - val_accuracy: 0.6771\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.6858 - val_loss: 0.5896 - val_accuracy: 0.6771\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.6858 - val_loss: 0.5891 - val_accuracy: 0.6771\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5785 - accuracy: 0.6858 - val_loss: 0.5886 - val_accuracy: 0.6875\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5780 - accuracy: 0.6858 - val_loss: 0.5880 - val_accuracy: 0.6875\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6858 - val_loss: 0.5875 - val_accuracy: 0.6875\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.6858 - val_loss: 0.5870 - val_accuracy: 0.6875\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.6858 - val_loss: 0.5865 - val_accuracy: 0.6875\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.6858 - val_loss: 0.5860 - val_accuracy: 0.6875\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5754 - accuracy: 0.6858 - val_loss: 0.5854 - val_accuracy: 0.6875\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.6858 - val_loss: 0.5849 - val_accuracy: 0.6875\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.6858 - val_loss: 0.5844 - val_accuracy: 0.6875\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5738 - accuracy: 0.6858 - val_loss: 0.5839 - val_accuracy: 0.6875\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.6875 - val_loss: 0.5834 - val_accuracy: 0.6875\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.6892 - val_loss: 0.5829 - val_accuracy: 0.6875\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5723 - accuracy: 0.6892 - val_loss: 0.5824 - val_accuracy: 0.6875\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5718 - accuracy: 0.6875 - val_loss: 0.5819 - val_accuracy: 0.6875\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6875 - val_loss: 0.5814 - val_accuracy: 0.6875\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.6875 - val_loss: 0.5809 - val_accuracy: 0.6875\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.6910 - val_loss: 0.5804 - val_accuracy: 0.6927\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.6910 - val_loss: 0.5799 - val_accuracy: 0.6979\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.6910 - val_loss: 0.5794 - val_accuracy: 0.6979\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.6927 - val_loss: 0.5790 - val_accuracy: 0.6979\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.6927 - val_loss: 0.5785 - val_accuracy: 0.7031\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.6910 - val_loss: 0.5780 - val_accuracy: 0.7031\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.6927 - val_loss: 0.5775 - val_accuracy: 0.7031\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.6927 - val_loss: 0.5770 - val_accuracy: 0.7083\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5664 - accuracy: 0.6927 - val_loss: 0.5766 - val_accuracy: 0.7083\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.6962 - val_loss: 0.5761 - val_accuracy: 0.7135\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.6962 - val_loss: 0.5756 - val_accuracy: 0.7135\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.6962 - val_loss: 0.5752 - val_accuracy: 0.7135\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5645 - accuracy: 0.6962 - val_loss: 0.5747 - val_accuracy: 0.7135\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5640 - accuracy: 0.6979 - val_loss: 0.5742 - val_accuracy: 0.7188\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.6979 - val_loss: 0.5738 - val_accuracy: 0.7188\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5631 - accuracy: 0.6979 - val_loss: 0.5733 - val_accuracy: 0.7188\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.6997 - val_loss: 0.5728 - val_accuracy: 0.7188\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.6997 - val_loss: 0.5724 - val_accuracy: 0.7188\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7014 - val_loss: 0.5719 - val_accuracy: 0.7188\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.7014 - val_loss: 0.5715 - val_accuracy: 0.7188\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7014 - val_loss: 0.5710 - val_accuracy: 0.7240\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.6997 - val_loss: 0.5706 - val_accuracy: 0.7240\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.6997 - val_loss: 0.5701 - val_accuracy: 0.7240\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5594 - accuracy: 0.6997 - val_loss: 0.5697 - val_accuracy: 0.7240\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.6997 - val_loss: 0.5693 - val_accuracy: 0.7240\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5585 - accuracy: 0.6997 - val_loss: 0.5688 - val_accuracy: 0.7240\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.6997 - val_loss: 0.5684 - val_accuracy: 0.7240\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5576 - accuracy: 0.6997 - val_loss: 0.5680 - val_accuracy: 0.7240\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.6997 - val_loss: 0.5675 - val_accuracy: 0.7292\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.6997 - val_loss: 0.5671 - val_accuracy: 0.7292\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5563 - accuracy: 0.7014 - val_loss: 0.5667 - val_accuracy: 0.7292\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5559 - accuracy: 0.7031 - val_loss: 0.5662 - val_accuracy: 0.7292\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5554 - accuracy: 0.7031 - val_loss: 0.5658 - val_accuracy: 0.7292\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5550 - accuracy: 0.7031 - val_loss: 0.5654 - val_accuracy: 0.7292\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5546 - accuracy: 0.7031 - val_loss: 0.5650 - val_accuracy: 0.7292\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7049 - val_loss: 0.5646 - val_accuracy: 0.7292\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7014 - val_loss: 0.5641 - val_accuracy: 0.7292\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7014 - val_loss: 0.5637 - val_accuracy: 0.7292\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5529 - accuracy: 0.7014 - val_loss: 0.5633 - val_accuracy: 0.7292\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7014 - val_loss: 0.5629 - val_accuracy: 0.7344\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5520 - accuracy: 0.7014 - val_loss: 0.5625 - val_accuracy: 0.7344\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.7014 - val_loss: 0.5621 - val_accuracy: 0.7344\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.6997 - val_loss: 0.5617 - val_accuracy: 0.7344\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.6979 - val_loss: 0.5613 - val_accuracy: 0.7344\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.6997 - val_loss: 0.5609 - val_accuracy: 0.7344\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.6979 - val_loss: 0.5605 - val_accuracy: 0.7344\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5495 - accuracy: 0.7031 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7031 - val_loss: 0.5597 - val_accuracy: 0.7344\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7031 - val_loss: 0.5593 - val_accuracy: 0.7396\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7049 - val_loss: 0.5589 - val_accuracy: 0.7448\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5479 - accuracy: 0.7049 - val_loss: 0.5585 - val_accuracy: 0.7448\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.7066 - val_loss: 0.5581 - val_accuracy: 0.7448\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7066 - val_loss: 0.5577 - val_accuracy: 0.7500\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5467 - accuracy: 0.7066 - val_loss: 0.5573 - val_accuracy: 0.7500\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7066 - val_loss: 0.5570 - val_accuracy: 0.7500\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7066 - val_loss: 0.5566 - val_accuracy: 0.7500\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7083 - val_loss: 0.5562 - val_accuracy: 0.7500\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7083 - val_loss: 0.5558 - val_accuracy: 0.7500\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7083 - val_loss: 0.5555 - val_accuracy: 0.7448\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7101 - val_loss: 0.5551 - val_accuracy: 0.7448\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7135 - val_loss: 0.5547 - val_accuracy: 0.7500\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7153 - val_loss: 0.5543 - val_accuracy: 0.7500\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7153 - val_loss: 0.5540 - val_accuracy: 0.7500\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7205 - val_loss: 0.5536 - val_accuracy: 0.7500\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7205 - val_loss: 0.5532 - val_accuracy: 0.7500\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7205 - val_loss: 0.5529 - val_accuracy: 0.7552\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7205 - val_loss: 0.5525 - val_accuracy: 0.7552\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7205 - val_loss: 0.5521 - val_accuracy: 0.7604\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7205 - val_loss: 0.5518 - val_accuracy: 0.7552\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7205 - val_loss: 0.5514 - val_accuracy: 0.7552\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7188 - val_loss: 0.5511 - val_accuracy: 0.7552\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7205 - val_loss: 0.5507 - val_accuracy: 0.7552\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7205 - val_loss: 0.5504 - val_accuracy: 0.7552\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.7240 - val_loss: 0.5500 - val_accuracy: 0.7552\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.7240 - val_loss: 0.5497 - val_accuracy: 0.7500\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5384 - accuracy: 0.7240 - val_loss: 0.5493 - val_accuracy: 0.7500\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7240 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7257 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7257 - val_loss: 0.5483 - val_accuracy: 0.7500\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7292 - val_loss: 0.5480 - val_accuracy: 0.7500\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7292 - val_loss: 0.5476 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "# Fit(Train) the Model\n",
        "\n",
        "# Compile the model with Optimizer, Loss Function and Metrics\n",
        "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
        "\n",
        "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
        "# the fit function returns the run history. \n",
        "# It is very convenient, as it contains information about the model fit, iterations etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vHEN8dcrIyDE"
      },
      "outputs": [],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "# y_pred_class_nn_1 = model_1.predict_classes(X_test_norm) > Sequential.predict_classes() depricated\n",
        "y_pred_class_nn_1 = np.argmax(model_1.predict(X_test_norm),axis=1)\n",
        "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2bejTjtUIyDF",
        "outputId": "6ee39850-6a5a-4312-cb87-010536047c63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bePbGiDnIyDG",
        "outputId": "91e1240e-8b72-47c4-8bdb-35de8bd075c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.34534073],\n",
              "       [0.44176707],\n",
              "       [0.3664376 ],\n",
              "       [0.3206042 ],\n",
              "       [0.29889983],\n",
              "       [0.4140898 ],\n",
              "       [0.189076  ],\n",
              "       [0.28397202],\n",
              "       [0.57622075],\n",
              "       [0.28506893]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vA_86zPYIyDH",
        "outputId": "9d34b754-fb7b-4968-9da8-29fe686c7931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.641\n",
            "roc-auc is 0.809\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Print model performance and plot the roc curve\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAPaHubKIyDJ"
      },
      "source": [
        "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIuqVw9yIyDJ"
      },
      "source": [
        "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "USSwBPQcIyDK",
        "outputId": "495610be-4b4e-40d4-d2c6-ce6f564375fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po_6xMYmIyDL"
      },
      "source": [
        "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ysvuP9pmIyDL",
        "outputId": "0f80cb54-9b31-469f-f482-222cbdb9d7b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f45a0f05590>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hU5bn38e+dhIPbsxCrBdngu8HWyjmCoyKBeEC0Uk8IWiEionhAbavW2lY2ysZTq7X1BAi2lkq1rbxYtFTZUKxiC3hC8ISIJdYqxor6KoQk9/vHWgPDmElmkjll8vtcVy4ya9bMejIJv3nmfp71LHN3RESkcBXlugEiIpJZCnoRkQKnoBcRKXAKehGRAqegFxEpcCW5bkC8zp07e/fu3XPdDBGRVmX16tUfuntpQ/flXdB3796dVatW5boZIiKtipm9k+g+lW5ERAqcgl5EpMAp6EVEClze1ehFJHu2b99OVVUVW7duzXVTJEkdO3aka9eutGvXLunHKOhF2rCqqir23HNPunfvjpnlujnSBHenurqaqqoqevTokfTjVLoRacO2bt1Kp06dFPKthJnRqVOnlD+BFVTQr5i5hhknLGPFzDW5bopIq6GQb12a8/sqmNLN4tvWcPJVX6Meo8Ofa1jCGiKTeue6WSIiOVcwPfpnHn2fWkqop4Qa2rHs99W5bpKINKG6upp+/frRr18/DjjgALp06bLjdk1NTaOPXbVqFVOmTEnpeN27d+fDDz9sSZNbpYLp0Z84/itMf7aeeopoz3bKT++U6yaJSBM6derEiy++CMDUqVPZY489+N73vrfj/traWkpKGo6psrIyysrKstLO1q5gevSRSb2Z/J9PAMZvpm9U2UYkU1asgBkzgn8zoLKykosuuojBgwdz9dVX8/e//51IJEL//v058sgjef311wFYtmwZJ598MhC8SUyYMIHy8nIOPvhg7rzzzqSPt3HjRoYPH06fPn2oqKjgH//4BwCPPPIIhx12GH379uWYY44BYO3atQwaNIh+/frRp08f3nzzzTT/9JlRMD16gIsvdu66Bn755Ff5yjCIRHLdIpFW5IorIOxdJ7RlC7z8MtTXQ1ER9OkDe++deP9+/eCOO1JuSlVVFc8++yzFxcV88sknPP3005SUlPDUU0/xgx/8gN///vdfesxrr73G0qVL+fTTTznkkEOYPHlyUnPNL7vsMsaPH8/48eOZM2cOU6ZMYcGCBUybNo3FixfTpUsXPv74YwDuvfdeLr/8cs455xxqamqoq6tL+WfLhYLp0QN8fMgRGPUsWLY3FRUZ63CItF1btgQhD8G/W7Zk5DBnnnkmxcXF4SG3cOaZZ3LYYYdx5ZVXsnbt2gYfc9JJJ9GhQwc6d+7M/vvvz/vvv5/UsVasWMHZZ58NwLnnnstf//pXAI466igqKyuZNWvWjkCPRCL8z//8DzfffDPvvPMOu+22W0t/1KwoqB79X9aVAvWAUbPNWbbM1KsXSVYyPe8VK6CiAmpqoH17mDcvIx+dd9999x3f/+hHP2LYsGE8+uijbNy4kfLy8gYf06FDhx3fFxcXU1tb26I23Hvvvfztb39j0aJFDBw4kNWrV3P22WczePBgFi1axMiRI7nvvvsYPnx4i46TDUn16M1shJm9bmbrzez7CfYZbWbrzGytmf0mZvst4bZXzexOy+Ck3fJOa2hPMFJfXF9DeSfNpxdJq0gEliyBG24I/s1CT2rLli106dIFgAceeCDtz3/kkUcyf/58AObNm8eQIUMAeOuttxg8eDDTpk2jtLSUTZs2sWHDBg4++GCmTJnCqFGjePnll9PenkxoskdvZsXAXcBxQBWw0swWuvu6mH16AtcCR7n7v81s/3D7kcBRQJ9w178CQ4Fl6fwhoiLVf+RJnuB4/sQwlhGpfgnQoKxIWkUiWR0Au/rqqxk/fjw33ngjJ510Uoufr0+fPhQVBX3c0aNH8/Of/5zzzjuPW2+9ldLSUubOnQvAVVddxZtvvom7U1FRQd++fbn55pt58MEHadeuHQcccAA/+MEPWtyebDB3b3wHswgw1d1PCG9fC+DuM2L2uQV4w91nN/DYXwBHAwYsB85191cTHa+srMybfeGRFStg+HAqt97D7zmNayZ9TEVlN5VvRBJ49dVX+frXv57rZkiKGvq9mdlqd29wvmkypZsuwKaY21Xhtli9gF5m9oyZPWdmIwDcfQWwFHgv/FrcUMib2SQzW2VmqzZv3pxEkxKIROB//5dD96ziM/bi+tndNCgrIm1eumbdlAA9gXJgLDDLzPYxs/8Cvg50JXhzGG5mQ+If7O4z3b3M3ctKSxu85GHyIhG29j8CcOrrCQdlW/aUIiKtWTJB/y5wUMztruG2WFXAQnff7u5vA28QBP+pwHPu/pm7fwY8AWS8kHLcoE8opg5w2td/oUFZEWnTkgn6lUBPM+thZu2BMcDCuH0WEPTmMbPOBKWcDcA/gKFmVmJm7QgGYhPW59Mlsvc6buZqwPhv+28i1X/M9CFFRPJWk0Hv7rXApcBigpB+2N3Xmtk0Mzsl3G0xUG1m6whq8le5ezXwO+AtYA3wEvCSuz+WgZ9jVxUVTCm6m734mF9zDis6nZzxQ4qI5KukTphy98eBx+O2/Tjmewe+E37F7lMHXNjyZqYoEmHVuDv5fw/szsvem4orjCW9tSSCiLRNBbUEQqxlXc7GMcDYtlUDsiL5aNiwYSxevHiXbXfccQeTJ09O+Jjy8nKiU7BHjhy5Yx2aWFOnTuW2225r9NgLFixg3bodpwPx4x//mKeeeiqV5jcodrG1fFGwQV/e7W06UAM47q4BWZE8NHbs2B1npUbNnz+fsWPHJvX4xx9/nH322adZx44P+mnTpnHsscc267nyXcEGfaT6jyzhWL7JYzhFzJu7TfPpRdIgnasUn3HGGSxatGjHRUY2btzIP//5T4YMGcLkyZMpKyvjG9/4Btdff32Dj4+9kMj06dPp1asXRx999I6ljAFmzZrF4YcfTt++fTn99NP5/PPPefbZZ1m4cCFXXXUV/fr146233qKyspLf/e53ACxZsoT+/fvTu3dvJkyYwLZt23Yc7/rrr2fAgAH07t2b1157Lemf9aGHHqJ3794cdthhXHPNNQDU1dVRWVnJYYcdRu/evbn99tsBuPPOOzn00EPp06cPY8aMSfFV/bKCWtRsF+XlRDpO49KtP+cxvsndzw1kTkXWlucQaXVysUrxfvvtx6BBg3jiiScYNWoU8+fPZ/To0ZgZ06dPZ7/99qOuro6Kigpefvll+vTp0+DzrF69mvnz5/Piiy9SW1vLgAEDGDhwIACnnXYaF1xwAQA//OEPuf/++7nssss45ZRTOPnkkznjjDN2ea6tW7dSWVnJkiVL6NWrF+PGjeOee+7hiiuuAKBz5848//zz3H333dx2223Mnj2bpvzzn//kmmuuYfXq1ey7774cf/zxLFiwgIMOOoh3332XV155BWBHGeqmm27i7bffpkOHDg2WplJVsD366Fmyq/ccBjiOUVODavUiLZCJVYpjyzexZZuHH36YAQMG0L9/f9auXbtLmSXe008/zamnnsp//Md/sNdee3HKKafsuO+VV15hyJAh9O7dm3nz5iVc5jjq9ddfp0ePHvTq1QuA8ePHs3z58h33n3baaQAMHDiQjRs3JvUzrly5kvLyckpLSykpKeGcc85h+fLlHHzwwWzYsIHLLruMP/3pT+y1115AsB7POeecw69//euEV9hKReH26AEiEcq/vZ4O99SwjY6419OpU+G+t4m0RK5WKR41ahRXXnklzz//PJ9//jkDBw7k7bff5rbbbmPlypXsu+++VFZWsnXr1mY9f2VlJQsWLKBv37488MADLGthby+6HHI6lkLed999eemll1i8eDH33nsvDz/8MHPmzGHRokUsX76cxx57jOnTp7NmzZoWBX7Bp15k+G7cyWUESyIYV0ypU61epJkysUrxHnvswbBhw5gwYcKO3vwnn3zC7rvvzt57783777/PE0880ehzHHPMMSxYsIAvvviCTz/9lMce23m6zqeffsqBBx7I9u3bmTdv3o7te+65J59++umXnuuQQw5h48aNrF+/HoAHH3yQoUOHtuhnHDRoEH/5y1/48MMPqaur46GHHmLo0KF8+OGH1NfXc/rpp3PjjTfy/PPPU19fz6ZNmxg2bBg333wzW7Zs4bPPPmvR8Qu7Rw/w5ptU0xmjHqeYmhpj2TLV6UWaKxOrFI8dO5ZTTz11Rwmnb9++9O/fn6997WscdNBBHHXUUY0+fsCAAZx11ln07duX/fffn8MPP3zHfTfccAODBw+mtLSUwYMH7wj3MWPGcMEFF3DnnXfuGIQF6NixI3PnzuXMM8+ktraWww8/nIsuuiiln2fJkiV07dp1x+1HHnmEm266iWHDhuHunHTSSYwaNYqXXnqJ8847j/qwHjZjxgzq6ur49re/zZYtW3B3pkyZ0uyZRVFNLlOcbS1aprghK1awYsjVVNQt5gt2o7gInv6rrjwlAlqmuLXKxDLFrVskQuSR77CECsr3XE1dPfzud1q6WETajsIPeoADDiBS9He+92kwF/f2n7rWqReRNqNtBP2yZeDOy/TBNNVSZBf5Vr6VxjXn99U2gr68HDp0oJxldGAbwbII0KlTrhsmklsdO3akurpaYd9KuDvV1dV07NgxpccV/mBs1IoVMHEiM98azkXb7sSB3XYznSkrbdr27dupqqpq9hx1yb6OHTvStWtX2rVrt8v2xgZjC396ZVQkAuedR/VV1Rh1OCVs3eosW6YZONJ2tWvXjh49euS6GZJhbaN0E7VtW1i+qQnm1TusW6dBWREpbG0r6IcPJ1KyiiVUMLYoODFj3jw0A0dEClpSQW9mI8zsdTNbb2bfT7DPaDNbZ2Zrzew3Mdu7mdmfzezV8P7u6Wl6M0Qi8OijROxvHFb6AQa4oxk4IlLQmgx6MysG7gJOBA4FxprZoXH79ASuBY5y928AV8Tc/SvgVnf/OjAI+CBNbW+eTp2gqIjy939LB7YSrIGjGTgiUriS6dEPAta7+wZ3rwHmA6Pi9rkAuMvd/w3g7h8AhG8IJe7+ZLj9M3f/PG2tb45wTn2E5/gZl1NkwVTLKVNUvhGRwpRM0HcBNsXcrgq3xeoF9DKzZ8zsOTMbEbP9YzP7g5m9YGa3hp8QdmFmk8xslZmt2rx5c3N+juSFc+qBYLEzMwC2bYMf/UhhLyKFJ12DsSVAT6AcGAvMMrN9wu1DgO8BhwMHA5XxD3b3me5e5u5lpaWlaWpSAtF1VkePppyltLcazIJzCZYs0cCsiBSeZIL+XeCgmNtdw22xqoCF7r7d3d8G3iAI/irgxbDsUwssAAa0vNktFInAJZcQ4TmW1JVznD0FBGG/dSv86le5bZ6ISDolE/QrgZ5m1sPM2gNjgIVx+ywg6M1jZp0JSjYbwsfuY2bRbvpwIPH1wLLpmWfAjAjPMdWn0r64Dghm4cydq169iBSOJoM+7IlfCiwGXgUedve1ZjbNzKIXZlwMVJvZOmApcJW7V7t7HUHZZomZrQEMmJWJHyRl5eUQrhcRYQUTjtp51fjt2zXdUkQKR9tZ66YhM2fC5MlQX8+KdsdQUfS/fLEtGCsePRquuELr4IhI69C2LzzSmOpqCGfdRLYvZ8l58zj33OCuhx/WwKyIFIa2HfTl5cGl7KNh/8H/5eu7v0NR+Kp88QVMnaqwF5HWrW0HfXSqZWVlcPsPf6B8zng6tKvbscuTT6pnLyKtW9sOegjCvmfPXUs4J/6EiorgbndNuRSR1k1BD0EJJ7qIvzuRJ37MDaPX0L79jk2acikirZaCHoJe/YQJO29v306k+o9MmLCjo8+2barXi0jrpKCPGjcOdtst+L6+Ht58k3H91xB7acY//xmOOSaYlSki0loo6KOiA7Onnx7cfuABIlcMZskdazj++J271dbCpZeqZy8irYeCPlYkAgMHBvWa8Iokkeo/MnUqlMRcXbe2VmUcEWk9FPTxYpZGoK4ONm4kwgruumtn2Ltr2qWItB4K+njREs5xxwW3Z82Cigom9V7B8uUwdGiwWdMuRaS1UNA3JBIJevawS6JHIjBjBrtMu5w9O1guRz17EclXCvpEhg2joYn00ZmY0WmXtbVw330q44hI/lLQJxI/tz5mIv24cUEZPxr2KuOISD5T0Dcmdm497BiBjbCCJUvgwgt3HaCdNUtlHBHJPwr6xkQHZocNC27H1evvuQcmTtzZs6+rUxlHRPKPgr4pkQhMn77LWjixC9+ojCMi+S6poDezEWb2upmtN7PvJ9hntJmtM7O1ZvabuPv2MrMqM/tFOhqddZEInH/+zts1NTvq9dFO/4UX7vpeMGsWXHSRevYikntNBr2ZFQN3AScChwJjzezQuH16AtcCR7n7N4Ar4p7mBmB5WlqcK7H1+rgzpqJlnPPP/3IZR2vjiEiuJdOjHwSsd/cN7l4DzAdGxe1zAXCXu/8bwN0/iN5hZgOBrwB/Tk+TcyTadR8+PLjdQI0mvowDwfTLiy/WIK2I5E4yQd8F2BRzuyrcFqsX0MvMnjGz58xsBICZFQE/Ab6XjsbmXCQCN97Y4Pz66N3RMk5x8c6HaZBWRHIpXYOxJUBPoBwYC8wys32Ai4HH3b2qsQeb2SQzW2VmqzZv3pymJmVIQ/Prr79+l7C/5x64++6gZq9BWhHJtWSC/l3goJjbXcNtsaqAhe6+3d3fBt4gCP4IcKmZbQRuA8aZ2U3xB3D3me5e5u5lpaWlzfgxsixar4+m+JNPfqkYP2kS/OUvX55rP3OmBmlFJLuSCfqVQE8z62Fm7YExwMK4fRYQ9OYxs84EpZwN7n6Ou3dz9+4E5ZtfuXuDs3ZalfiFz6DBheobmmtfX69BWhHJriaD3t1rgUuBxcCrwMPuvtbMppnZKeFui4FqM1sHLAWucvfqTDU6L0QifGmh+u3bG1yoPtEg7eTJGqQVkcwzd891G3ZRVlbmq1atynUzkjdzJlxySZDcEKR5x45Bjz8S2bHbihVBfX7WrGBwNlb79kHZf9y4XR4iIpI0M1vt7mUN3aczY1tq0iRYvhyOPTa4nWDUNdEgLQTnX917r8o5IpIZCvp0iERg2rRdp10mWOEsdpC2QwfNuReRzFPQp0v8QvV1dUE3vYHJ89He/dKlDc+5V+9eRNJJQZ9ODY26NjJ5PracEzumC+rdi0j6KOjTqbEVzhpJ7GiZ/6KLoCjmN6IzakUkHRT06ZZohbMm6jHRh91zz669e51RKyItpaDPlEST5y+5pNHueWzvPlq7j55Re8EF6tmLSOoU9JmSaIWz2lr40Y8aTexo7/6CC3Y9o3b2bBgyRIO0IpIaBX0mxU+ej1qyJKlpNQ19KKirC3r755+v3r2IJEdBnw3RyfPHH79zWxJrICT6UOAOc+YEvftrroEZMxT6IpKYlkDIphUrgp58dLmEqCTWQJg5M1gzrbY2CPpYZsEbwV13Be8pItL2aAmEfBGJBGnc0BoITcyjjD2jNrZ3D0Hwa969iCSioM+2+DUQopKYR9nYejmgs2pFpGEq3eRSQ0taFhcH022aWMpyxQpYtgw+/hhuvz1YITlWkk8jIgWisdKNgj4fTJ4clG5ifxclJUkX3RtbAjmFpxGRVkw1+nyX6OSqJIvujZV0VLsXEQV9Pkg0jzLFonuiAdvo05SXK/BF2iIFfb5IU7dcFzgRkXhJBb2ZjTCz181svZk1eHFvMxttZuvMbK2Z/Sbc1s/MVoTbXjazs9LZ+ILUVLe8Gb17XeBEpI1z90a/gGLgLeBgoD3wEnBo3D49gReAfcPb+4f/9gJ6ht9/FXgP2Kex4w0cONAldN997u3auQfDtDu/iovdL7rI/dlnk3qaZ58Ndi8u/vJTlZQEhxGR1g1Y5QlyNZke/SBgvbtvcPcaYD4wKm6fC4C73P3f4ZvHB+G/b7j7m+H3/wQ+AEqb8X7UNkW75bFLWULKC9U3VRWaPDk4hHr3IoUpmaDvAmyKuV0VbovVC+hlZs+Y2XNmNiL+ScxsEMEngrcauG+Sma0ys1WbN29OvvVtQaKF0ZqxUH2iqlB9ffC+obVzRApTugZjSwjKN+XAWGCWme0TvdPMDgQeBM5z9/r4B7v7THcvc/ey0lJ1+BvUUO/ePUjoFJaybKx3X1cHt9wC112nAVuRQpJM0L8LHBRzu2u4LVYVsNDdt7v728AbBMGPme0FLAKuc/fnWt7kNqyhhepjl7JMIZm1do5I25FM0K8EeppZDzNrD4wBFsbts4CgN4+ZdSYo5WwI938U+JW7/y5trW7r0rRQvdbOEWkbmgx6d68FLgUWA68CD7v7WjObZmanhLstBqrNbB2wFLjK3auB0cAxQKWZvRh+9cvIT9KWJLNQfTN699Onw9VXJx6wVe9epHXSWjetXWML1Y8bF/TyU1zVTGvniLQ+WtSs0DWWzEVFQX2mGcmc6D3EDE46Cbp21eqYIvlCQd9WNNa7HzMGhg2D6upg0Zsk07mx9xAIyjznn6/AF8k1BX1b0lQyN/O6g429h4BKOiK5pmWK25KmptI0c+5k7HTM2PO2ojRgK5K/1KMvZNHe/dy5wSWo6r90rlqzuuLRp/3Xv+Cxx778wSGJa52LSJqpdNPWxV538Kc/DbrfsVpw3cHGSjolJfCd78A++6Q0LCAizaCgl50yMHcy9oNDTc2XA7+ZwwIikgLV6GWnRIukQbPXPYg+5dKlWlJBJB8p6NuqxpZAbua6B1pSQSQ/qXQjiQvtRUXBG0IzavexwwK33x6MBccqKoJvfhMOPFCDtiLpoBq9NC2D6x7opCuRzFPQS/IaW/fgxBOhW7dmJ7JOuhLJHA3GSvISLVTvDo8/HhTZhw5t1qhqMiddacBWJP3Uo5fEMtgFb+qkK83BF0mNSjfSfNFEvv/+L4+oQotOtopq7P1Ec/BFkqOgl5ZLpguewQHbNLyfiBQ0Bb2kV2MDthMnwnnnZaR3DxqwFUmkxUFvZiOAnwHFwGx3v6mBfUYDUwEHXnL3s8Pt44Efhrvd6O6/bOxYCvpWoqnpmOefD+PHNyvw4+fgN/R+cu65cNRRKS+vL1KwWhT0ZlYMvAEcB1QRXCx8rLuvi9mnJ/AwMNzd/21m+7v7B2a2H7AKKCN4A1gNDHT3fyc6noK+lWmsC15cDN/9botGVDO0vL5IwWnp9MpBwHp33+DuNcB8YFTcPhcAd0UD3N0/CLefADzp7h+F9z0JjGjODyF5KnbOZIcOu657UFcHt9wC113X7HUPMrS8vkibkkzQdwE2xdyuCrfF6gX0MrNnzOy5sNST7GMxs0lmtsrMVm3evDn51kt+yMKqZvHvJ0Vxf7mx6+hccw3MmKHQF4lK1wlTJUBPoBwYC8wys32SfbC7z3T3MncvKy0tTVOTJOsyvKpZ7PvJjTfC1Vd/+TC1tS3+ECFScEqS2Odd4KCY213DbbGqgL+5+3bgbTN7gyD43yUI/9jHLmtuY6WVmDQJevdOPKJaWxusmrloEXz1qynPmYxEdu7+rW81XMOP/RDxwgualiltWzKDsSUEg7EVBMG9Ejjb3dfG7DOCYIB2vJl1Bl4A+rFzAHZAuOvzBIOxHyU6ngZjC1AWVjVLZlqmzrSVQpaO6ZUjgTsIplfOcffpZjYNWOXuC83MgJ8QDLTWAdPdfX742AnAD8Knmu7ucxs7loK+gGV4knxT0zJBs3SkcOmEKckfTS2pUFQUnALbzDn48YfRmbbSVijoJf80taRCGubgQ9MfItJ0GJGcU9BLfsuDkk4aDiOSUwp6yX9ZqrU0dRhd4lBaKwW9tB5ZWtWsqcOALnEorYuCXlqXZGot55wTnBHVglXNki3ptG8PEyYo8CW/Keil9crSqmZNTQYCzcWX/Kagl9Yvmekzaazh/+tf8MQTUFOjufjSOijopTBEU3ju3KDbXV//5X3S2O1OZnz4m9+EAw5QWUdyT0EvhSXLp8Bq4FZaAwW9FK4sTsvUXHzJZwp6KXxZXNWsqYFbMzjxROjWTT18yR4FvbQNWS7pNLWKAwTvLxMnKvAl8xT00vZkeVUzrakjuaagl7Yrj0o6sYdUHV/STUEvbVselnRUx5d0U9CLROVZSQdUx5f0UNCLxMtiUT2VqZknnaSVM6V5FPQiDUm2pNOuXdpWNUu2jq8TsCRV6bhm7AjgZwTXjJ3t7jfF3V8J3Epw8XCAX7j77PC+W4CTgCLgSeByb+SgCnrJiaZKOpCRgdvG1tRJ8yGlwLUo6M2sGHgDOA6oAlYCY919Xcw+lUCZu18a99gjCd4Ajgk3/RW41t2XJTqegl5yKpmieppXNUtlto5CXxJpLOhLknj8IGC9u28In2w+MApY1+ijAg50BNoDBrQD3k+m0SI5MWkS9O4dlHQ6dYIXXvhyL989eCO4+OLg/hbWVyKR4GvcuMZn69TWwi23aPVMSV0yPfozgBHuPjG8fS4wOLb3HvboZwCbCXr/V7r7pvC+24CJBEH/C3e/roFjTAImAXTr1m3gO++80/KfTCRdsjgXP9lDgi57KLtqaekmmaDvBHzm7tvM7ELgLHcfbmb/RVDbPyvc9Ungand/OtHxVLqRvJSDVc2SPSRo8FZaHvQRYKq7nxDevhbA3Wck2L8Y+Mjd9zazq4CO7n5DeN+Pga3ufkui4ynoJe/l4ArjqbzPqI7fNrU06EsIyjEVBLNqVgJnu/vamH0OdPf3wu9PBa5x9yPM7CzgAmAEQenmT8Ad7v5YouMp6KXVyNFC9Rq8lYakY3rlSOAOgumVc9x9uplNA1a5+0IzmwGcAtQCHwGT3f21sHd/N8GsGwf+5O7faexYCnppVXK4UH0ySy2ABm/bCp0wJZINySxUf/zx0KNH2ovpyQ7eTpwIAwdCdbV6+YVGQS+STcl0tTNwwdlUBm/Vyy88CnqRXMlhHT+Z0C8qgpNPhq9+VTN2WjsFvUguJTt62r592tbUaejwc+cGh6+vb3i/kpIg9NP4IUOySEEvkg9iSzqLFiUO/QxNl9G8/MKmoBfJN6msapaBQnqyHzJ0CcTWQ0Evks+aOphqPJUAAAs+SURBVAHLLKipdOmSsbJOUx8yQPPy852CXqQ1SPZyVBkqpCc7Lz/aDIV+flHQi7QWeVJIT+Y9BzRNM58o6EVaoxyvdZDKe05REYwcCV27agA3VxT0Iq1ZsoX0DHavUwn94uLgg4bOwM0uBb1IoUimkF5UFFxlPAODt9EmJBv6oHp+tijoRQpRsoO3EydmrJ6SbHUJVM/PNAW9SKFKtntdXAyXXw6dO2ekWx1/WkBjZ+Cqnp8ZCnqRtiDZ7nW7dkFpJ0NrHaRazz/5ZF0OMR0U9CJtSSoT4jO81kEqoV9SErz/KPSbR0Ev0lbF1/HNEpd2MrzWQSr1fC2wljoFvUhbFu1Wd+oEL7yQ82sQprLsQrQ5Cv2mpeNSgiOAnxFcSnC2u98Ud38lcCvBNWUBfuHus8P7ugGzgYMILic40t03JjqWgl4kw1Jd6yCD02RSDf1opal/f83Rj9fSi4MXE1wc/DigiuDi4GPdfV3MPpVAmbtf2sDjlwHT3f1JM9sDqHf3zxMdT0EvkkXJTNE0C4rnGZ4mk2roR6drao5+oKVBHwGmuvsJ4e1rAdx9Rsw+lTQQ9GZ2KDDT3Y9OtrEKepEsy8NpMs0N/bY8R7+lQX8GMMLdJ4a3zwUGx4Z6GPQzgM0Evf8r3X2TmX0LmAjUAD2Ap4Dvu3td3DEmAZMAunXrNvCdd95pzs8pIi2VJ4uqxTcplTn6GTwpOK9lI+g7AZ+5+zYzuxA4y92Hh4+9H+gP/AP4LfC4u9+f6Hjq0YvkiTy8OkmqHz5Gjmw7oZ/x0k3c/sXAR+6+t5kdAdzs7kPD+84FjnD3SxIdT0Evkmfy9OokCv1dtTToSwjKMRUEs2pWAme7+9qYfQ509/fC708FrnH3I8LQfx441t03m9lcYJW735XoeAp6kTyW7Iwds6C0M3JkVuZFpjJHv1BDPx3TK0cCdxBMr5zj7tPNbBpBaC80sxnAKUAt8BEw2d1fCx97HPATwIDVwCR3r0l0LAW9SCuR7NVJICf1/GQGcYuL4cQTC2PdHZ0wJSKZkcdrFjcn9E84Abp1a52hr6AXkczLszNw45uWauiffTYcfXTrOTFLQS8i2ZdKPT+LZz6lGvqw8z3pk0+C2/nY41fQi0hu5enVxpsT+pDxlZ6bRUEvIrmX6tXGR4zIasE8lROzYuVL6CvoRSS/5Pkk+FTHmKNyGfoKehHJX6mG/vnnw8CBWRsljR9jztfllRX0ItI6pHLmE2R15k6s5sziyfRacAp6EWldWjI1phWEfiYqUQp6EWm9Uh0lzeGaxc0J/bPOgqFDg7IQND/8FfQiUhhSqeebBae6du+ek+kwzZ262aEDLF2aenMV9CJSeFIdxM3h+gaphL4ZTJ8O116b2jEU9CJS2PJ8umZ8UxurRKlHLyLSlFTXLM7CpRETiZ+6CarRi4gkLx/nQGaQgl5E2rbmhH6WT8xqKQW9iEhUK5qjnwoFvYhIQwoo9NNxKcERwM8ILiU4291viru/EriV4JqyAL9w99kx9+8FrAMWuPuljR1LQS8iOdGc5SvzKPQbC/qSJB5cDNwFHAdUASvNbKG7r4vb9beNhPgNwPIU2iwikl2RyM6gTna6Zm0t3HJL8H0ehX68JoMeGASsd/cNAGY2HxhF0ENvkpkNBL4C/Alo8N1GRCSvxIb+t77V6kM/maDvAmyKuV0FDG5gv9PN7BjgDeBKd99kZkXAT4BvA8cmOoCZTQImAXTr1i3JpouIZEEBhH4yQZ+Mx4CH3H2bmV0I/BIYDlwMPO7uVWaW8MHuPhOYCUGNPk1tEhFJr5aGfnExfPe7Wb/4bJODsWYWAaa6+wnh7WsB3H1Ggv2LgY/cfW8zmwcMAeqBPYD2wN3u/v1Ex9NgrIi0Oi25JNX550P//i2er9+iWTdmVkJQjqkgmFWzEjjb3dfG7HOgu78Xfn8qcI27HxH3PJVAmWbdiEhBa27ot3B55RbNunH3WjO7FFhMML1yjruvNbNpwCp3XwhMMbNTgFrgI6Ay5VaKiBSC5pR3INheWwuXXgq9e6e1pKMTpkREsqGhi882NF+/qAhuvDHldYpb1KMXEZE0iO3pR8WXeerqgnWKy8vTemgFvYhIrjRU5snAFEwFvYhIPmiox58mRRl5VhERyRsKehGRAqegFxEpcAp6EZECp6AXESlwCnoRkQKXd2fGmtlm4J0WPEVn4MM0NSed1K7U5Gu7IH/bpnalJl/bBc1r23+6e2lDd+Rd0LeUma1KdBpwLqldqcnXdkH+tk3tSk2+tgvS3zaVbkRECpyCXkSkwBVi0M/MdQMSULtSk6/tgvxtm9qVmnxtF6S5bQVXoxcRkV0VYo9eRERiKOhFRApcwQS9mY0ws9fNbL2ZJbz4eBbacZCZLTWzdWa21swuD7dPNbN3zezF8Gtkjtq30czWhG1YFW7bz8yeNLM3w3/3zXKbDol5XV40s0/M7IpcvGZmNsfMPjCzV2K2Nfj6WODO8G/uZTMbkOV23Wpmr4XHftTM9gm3dzezL2Jet3sz1a5G2pbwd2dm14av2etmdkKW2/XbmDZtNLMXw+1Ze80ayYjM/Z25e6v/IriW7VvAwUB74CXg0By15UBgQPj9ngQXVj8UmAp8Lw9eq41A57httwDfD7//PnBzjn+X/wL+MxevGXAMMAB4panXBxgJPAEYcATwtyy363igJPz+5ph2dY/dL0evWYO/u/D/wktAB6BH+P+2OFvtirv/J8CPs/2aNZIRGfs7K5Qe/SBgvbtvcPcaYD4wKhcNcff33P358PtPgVeBLrloSwpGAb8Mv/8l8K0ctqUCeMvdW3J2dLO5+3KCC9zHSvT6jAJ+5YHngH3M7MBstcvd/+zuteHN54CumTh2UxK8ZomMAua7+zZ3fxtYT/D/N6vtMjMDRgMPZeLYjWkkIzL2d1YoQd8F2BRzu4o8CFcz6w70B/4Wbro0/Og1J9vlkRgO/NnMVpvZpHDbV9z9vfD7fwFfyU3TABjDrv/58uE1S/T65NPf3QSCXl9UDzN7wcz+YmZDctSmhn53+fKaDQHed/c3Y7Zl/TWLy4iM/Z0VStDnHTPbA/g9cIW7fwLcA/wfoB/wHsHHxlw42t0HACcCl5jZMbF3evBZMSdzbs2sPXAK8Ei4KV9esx1y+fokYmbXAbXAvHDTe0A3d+8PfAf4jZntleVm5d3vLs5Ydu1QZP01ayAjdkj331mhBP27wEExt7uG23LCzNoR/ALnufsfANz9fXevc/d6YBYZ+rjaFHd/N/z3A+DRsB3vRz8Khv9+kIu2Ebz5PO/u74dtzIvXjMSvT87/7sysEjgZOCcMB8KySHX4/WqCOnivbLarkd9dPrxmJcBpwG+j27L9mjWUEWTw76xQgn4l0NPMeoS9wjHAwlw0JKz93Q+86u4/jdkeW1M7FXgl/rFZaNvuZrZn9HuCwbxXCF6r8eFu44H/m+22hXbpZeXDaxZK9PosBMaFsyKOALbEfPTOODMbAVwNnOLun8dsLzWz4vD7g4GewIZstSs8bqLf3UJgjJl1MLMeYdv+ns22AccCr7l7VXRDNl+zRBlBJv/OsjHKnI0vgpHpNwjeia/LYTuOJvjI9TLwYvg1EngQWBNuXwgcmIO2HUww4+ElYG30dQI6AUuAN4GngP1y0LbdgWpg75htWX/NCN5o3gO2E9RCz0/0+hDMgrgr/JtbA5RluV3rCWq30b+ze8N9Tw9/vy8CzwPfzMFrlvB3B1wXvmavAydms13h9geAi+L2zdpr1khGZOzvTEsgiIgUuEIp3YiISAIKehGRAqegFxEpcAp6EZECp6AXESlwCnoRkQKnoBcRKXD/H+YCAG7kAxfxAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R6phvyzIyDM"
      },
      "source": [
        "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "scrolled": true,
        "id": "Ud35EZoOIyDN",
        "outputId": "9d2e6f8a-8a23-44a4-edf3-80eddd229695",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.7292 - val_loss: 0.5473 - val_accuracy: 0.7500\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7292 - val_loss: 0.5469 - val_accuracy: 0.7500\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7292 - val_loss: 0.5466 - val_accuracy: 0.7500\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5352 - accuracy: 0.7292 - val_loss: 0.5463 - val_accuracy: 0.7500\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5349 - accuracy: 0.7292 - val_loss: 0.5460 - val_accuracy: 0.7500\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7292 - val_loss: 0.5456 - val_accuracy: 0.7500\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.7292 - val_loss: 0.5453 - val_accuracy: 0.7500\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7309 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7309 - val_loss: 0.5446 - val_accuracy: 0.7500\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5332 - accuracy: 0.7309 - val_loss: 0.5443 - val_accuracy: 0.7500\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7309 - val_loss: 0.5440 - val_accuracy: 0.7500\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5325 - accuracy: 0.7309 - val_loss: 0.5437 - val_accuracy: 0.7500\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7309 - val_loss: 0.5434 - val_accuracy: 0.7500\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7344 - val_loss: 0.5431 - val_accuracy: 0.7500\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7344 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.7344 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5308 - accuracy: 0.7378 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7396 - val_loss: 0.5418 - val_accuracy: 0.7552\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7396 - val_loss: 0.5415 - val_accuracy: 0.7604\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.7396 - val_loss: 0.5412 - val_accuracy: 0.7656\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7378 - val_loss: 0.5409 - val_accuracy: 0.7604\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5292 - accuracy: 0.7378 - val_loss: 0.5406 - val_accuracy: 0.7604\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7378 - val_loss: 0.5403 - val_accuracy: 0.7604\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7413 - val_loss: 0.5400 - val_accuracy: 0.7604\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5282 - accuracy: 0.7431 - val_loss: 0.5397 - val_accuracy: 0.7604\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7431 - val_loss: 0.5394 - val_accuracy: 0.7604\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7465 - val_loss: 0.5391 - val_accuracy: 0.7604\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7465 - val_loss: 0.5388 - val_accuracy: 0.7604\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5270 - accuracy: 0.7465 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7448 - val_loss: 0.5382 - val_accuracy: 0.7604\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7448 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7448 - val_loss: 0.5376 - val_accuracy: 0.7604\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5258 - accuracy: 0.7413 - val_loss: 0.5373 - val_accuracy: 0.7604\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7413 - val_loss: 0.5370 - val_accuracy: 0.7604\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.7413 - val_loss: 0.5368 - val_accuracy: 0.7604\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7413 - val_loss: 0.5365 - val_accuracy: 0.7604\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7413 - val_loss: 0.5362 - val_accuracy: 0.7604\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.7413 - val_loss: 0.5359 - val_accuracy: 0.7604\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7413 - val_loss: 0.5356 - val_accuracy: 0.7604\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.7413 - val_loss: 0.5354 - val_accuracy: 0.7604\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5234 - accuracy: 0.7413 - val_loss: 0.5351 - val_accuracy: 0.7656\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7448 - val_loss: 0.5348 - val_accuracy: 0.7656\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.7465 - val_loss: 0.5345 - val_accuracy: 0.7656\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7483 - val_loss: 0.5343 - val_accuracy: 0.7656\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7483 - val_loss: 0.5340 - val_accuracy: 0.7656\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7500 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.7517 - val_loss: 0.5335 - val_accuracy: 0.7708\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7500 - val_loss: 0.5332 - val_accuracy: 0.7708\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7517 - val_loss: 0.5329 - val_accuracy: 0.7708\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5208 - accuracy: 0.7535 - val_loss: 0.5327 - val_accuracy: 0.7656\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7535 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7535 - val_loss: 0.5321 - val_accuracy: 0.7656\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5199 - accuracy: 0.7517 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7517 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7500 - val_loss: 0.5314 - val_accuracy: 0.7656\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7500 - val_loss: 0.5311 - val_accuracy: 0.7708\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7500 - val_loss: 0.5309 - val_accuracy: 0.7708\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5185 - accuracy: 0.7517 - val_loss: 0.5306 - val_accuracy: 0.7656\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5183 - accuracy: 0.7517 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7517 - val_loss: 0.5301 - val_accuracy: 0.7656\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5177 - accuracy: 0.7517 - val_loss: 0.5299 - val_accuracy: 0.7656\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.7535 - val_loss: 0.5296 - val_accuracy: 0.7552\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7535 - val_loss: 0.5294 - val_accuracy: 0.7604\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.7535 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7535 - val_loss: 0.5289 - val_accuracy: 0.7656\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7535 - val_loss: 0.5286 - val_accuracy: 0.7656\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5161 - accuracy: 0.7535 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7517 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7517 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7517 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7517 - val_loss: 0.5274 - val_accuracy: 0.7604\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7517 - val_loss: 0.5272 - val_accuracy: 0.7604\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7517 - val_loss: 0.5270 - val_accuracy: 0.7604\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7517 - val_loss: 0.5267 - val_accuracy: 0.7604\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.7517 - val_loss: 0.5265 - val_accuracy: 0.7604\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5138 - accuracy: 0.7517 - val_loss: 0.5263 - val_accuracy: 0.7604\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7517 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7517 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7517 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7552 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5126 - accuracy: 0.7552 - val_loss: 0.5251 - val_accuracy: 0.7604\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7552 - val_loss: 0.5249 - val_accuracy: 0.7604\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7569 - val_loss: 0.5247 - val_accuracy: 0.7604\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.7552 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7569 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.7587 - val_loss: 0.5240 - val_accuracy: 0.7604\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7587 - val_loss: 0.5238 - val_accuracy: 0.7604\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7587 - val_loss: 0.5236 - val_accuracy: 0.7604\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7587 - val_loss: 0.5234 - val_accuracy: 0.7604\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7587 - val_loss: 0.5232 - val_accuracy: 0.7604\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7587 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7604 - val_loss: 0.5227 - val_accuracy: 0.7604\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7604 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7604 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7604 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7604 - val_loss: 0.5219 - val_accuracy: 0.7656\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7639 - val_loss: 0.5217 - val_accuracy: 0.7656\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7656\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7639 - val_loss: 0.5213 - val_accuracy: 0.7656\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5081 - accuracy: 0.7639 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7639 - val_loss: 0.5209 - val_accuracy: 0.7656\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7639 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7639 - val_loss: 0.5205 - val_accuracy: 0.7656\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7639 - val_loss: 0.5203 - val_accuracy: 0.7656\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7639 - val_loss: 0.5201 - val_accuracy: 0.7656\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7622 - val_loss: 0.5199 - val_accuracy: 0.7656\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7622 - val_loss: 0.5197 - val_accuracy: 0.7656\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7622 - val_loss: 0.5195 - val_accuracy: 0.7656\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7622 - val_loss: 0.5193 - val_accuracy: 0.7656\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7639 - val_loss: 0.5191 - val_accuracy: 0.7656\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7622 - val_loss: 0.5189 - val_accuracy: 0.7656\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7674 - val_loss: 0.5187 - val_accuracy: 0.7656\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7674 - val_loss: 0.5186 - val_accuracy: 0.7656\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7691 - val_loss: 0.5184 - val_accuracy: 0.7656\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5049 - accuracy: 0.7691 - val_loss: 0.5182 - val_accuracy: 0.7604\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5046 - accuracy: 0.7656 - val_loss: 0.5180 - val_accuracy: 0.7656\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7656 - val_loss: 0.5178 - val_accuracy: 0.7656\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7656 - val_loss: 0.5176 - val_accuracy: 0.7656\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7656 - val_loss: 0.5174 - val_accuracy: 0.7656\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7656 - val_loss: 0.5173 - val_accuracy: 0.7656\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.7656 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.7674 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7674 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7674 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7674 - val_loss: 0.5164 - val_accuracy: 0.7708\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7674 - val_loss: 0.5162 - val_accuracy: 0.7708\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5024 - accuracy: 0.7674 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7674 - val_loss: 0.5159 - val_accuracy: 0.7708\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7674 - val_loss: 0.5157 - val_accuracy: 0.7708\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7674 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5017 - accuracy: 0.7674 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7656 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7656 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7656 - val_loss: 0.5148 - val_accuracy: 0.7760\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7674 - val_loss: 0.5147 - val_accuracy: 0.7760\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7691 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7674 - val_loss: 0.5143 - val_accuracy: 0.7760\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7691 - val_loss: 0.5142 - val_accuracy: 0.7760\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7691 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7674 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7691 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4995 - accuracy: 0.7691 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7691 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7691 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7691 - val_loss: 0.5130 - val_accuracy: 0.7760\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7691 - val_loss: 0.5129 - val_accuracy: 0.7760\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7691 - val_loss: 0.5127 - val_accuracy: 0.7760\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7691 - val_loss: 0.5126 - val_accuracy: 0.7760\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7691 - val_loss: 0.5124 - val_accuracy: 0.7760\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7691 - val_loss: 0.5123 - val_accuracy: 0.7760\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.7708 - val_loss: 0.5121 - val_accuracy: 0.7760\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7708 - val_loss: 0.5120 - val_accuracy: 0.7760\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7708 - val_loss: 0.5118 - val_accuracy: 0.7760\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4974 - accuracy: 0.7708 - val_loss: 0.5117 - val_accuracy: 0.7760\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4972 - accuracy: 0.7708 - val_loss: 0.5115 - val_accuracy: 0.7760\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7726 - val_loss: 0.5114 - val_accuracy: 0.7760\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7726 - val_loss: 0.5112 - val_accuracy: 0.7760\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7726 - val_loss: 0.5111 - val_accuracy: 0.7760\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7726 - val_loss: 0.5109 - val_accuracy: 0.7760\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7708 - val_loss: 0.5108 - val_accuracy: 0.7760\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7708 - val_loss: 0.5106 - val_accuracy: 0.7760\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7708 - val_loss: 0.5105 - val_accuracy: 0.7760\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.7708 - val_loss: 0.5103 - val_accuracy: 0.7760\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7708 - val_loss: 0.5102 - val_accuracy: 0.7760\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4955 - accuracy: 0.7708 - val_loss: 0.5101 - val_accuracy: 0.7760\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7726 - val_loss: 0.5099 - val_accuracy: 0.7760\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7726 - val_loss: 0.5098 - val_accuracy: 0.7760\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7726 - val_loss: 0.5096 - val_accuracy: 0.7760\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7726 - val_loss: 0.5095 - val_accuracy: 0.7760\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7726 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7726 - val_loss: 0.5092 - val_accuracy: 0.7760\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7726 - val_loss: 0.5091 - val_accuracy: 0.7760\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7726 - val_loss: 0.5090 - val_accuracy: 0.7760\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7726 - val_loss: 0.5088 - val_accuracy: 0.7760\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7726 - val_loss: 0.5087 - val_accuracy: 0.7760\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4938 - accuracy: 0.7726 - val_loss: 0.5086 - val_accuracy: 0.7760\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7726 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7726 - val_loss: 0.5083 - val_accuracy: 0.7760\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7726 - val_loss: 0.5082 - val_accuracy: 0.7760\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4931 - accuracy: 0.7726 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7726 - val_loss: 0.5079 - val_accuracy: 0.7760\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7726 - val_loss: 0.5078 - val_accuracy: 0.7760\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7726 - val_loss: 0.5077 - val_accuracy: 0.7760\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7726 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7726 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7726 - val_loss: 0.5073 - val_accuracy: 0.7760\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7726 - val_loss: 0.5072 - val_accuracy: 0.7760\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7726 - val_loss: 0.5070 - val_accuracy: 0.7760\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4918 - accuracy: 0.7726 - val_loss: 0.5069 - val_accuracy: 0.7760\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4916 - accuracy: 0.7726 - val_loss: 0.5068 - val_accuracy: 0.7760\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4915 - accuracy: 0.7726 - val_loss: 0.5067 - val_accuracy: 0.7760\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4913 - accuracy: 0.7726 - val_loss: 0.5065 - val_accuracy: 0.7760\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7708 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7726 - val_loss: 0.5063 - val_accuracy: 0.7760\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7726 - val_loss: 0.5062 - val_accuracy: 0.7760\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7726 - val_loss: 0.5061 - val_accuracy: 0.7760\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7726 - val_loss: 0.5060 - val_accuracy: 0.7760\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.7726 - val_loss: 0.5058 - val_accuracy: 0.7760\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7726 - val_loss: 0.5057 - val_accuracy: 0.7760\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7726 - val_loss: 0.5055 - val_accuracy: 0.7760\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7760\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7726 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7726 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7726 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7726 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7726 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7726 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7708 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7708 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7708 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4886 - accuracy: 0.7708 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7708 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7708 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7708 - val_loss: 0.5040 - val_accuracy: 0.7760\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7708 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7708 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4874 - accuracy: 0.7708 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7708 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7708 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.7708 - val_loss: 0.5029 - val_accuracy: 0.7760\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7708 - val_loss: 0.5028 - val_accuracy: 0.7760\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7708 - val_loss: 0.5027 - val_accuracy: 0.7760\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4865 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7760\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.7708 - val_loss: 0.5025 - val_accuracy: 0.7760\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7760\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7708 - val_loss: 0.5023 - val_accuracy: 0.7760\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7760\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7708 - val_loss: 0.5021 - val_accuracy: 0.7760\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7708 - val_loss: 0.5020 - val_accuracy: 0.7760\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7708 - val_loss: 0.5019 - val_accuracy: 0.7760\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7708 - val_loss: 0.5018 - val_accuracy: 0.7760\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7760\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7708 - val_loss: 0.5016 - val_accuracy: 0.7760\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7726 - val_loss: 0.5015 - val_accuracy: 0.7760\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7760\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7726 - val_loss: 0.5013 - val_accuracy: 0.7760\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7760\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7760\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7760\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7726 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4840 - accuracy: 0.7726 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7726 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7726 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7726 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4830 - accuracy: 0.7726 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7726 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7726 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7726 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7726 - val_loss: 0.4994 - val_accuracy: 0.7760\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7726 - val_loss: 0.4993 - val_accuracy: 0.7760\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7726 - val_loss: 0.4992 - val_accuracy: 0.7760\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7726 - val_loss: 0.4992 - val_accuracy: 0.7760\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7726 - val_loss: 0.4988 - val_accuracy: 0.7760\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7760\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.7708 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7726 - val_loss: 0.4986 - val_accuracy: 0.7760\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.4985 - val_accuracy: 0.7760\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7708 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7726 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7726 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7726 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7726 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.7726 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7743 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7726 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7743 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.7743 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7743 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7726 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7726 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7726 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.7726 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7726 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7726 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7726 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7726 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7726 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7726 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7726 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7726 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7726 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7726 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7726 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7726 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7760 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7760 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7760 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7760 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4759 - accuracy: 0.7760 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7760 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7760 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7760 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.7743 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7760 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7760 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7760 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7795 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7795 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7795 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7795 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7795 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7795 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.7795 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7795 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7795 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.7812 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7795 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7795 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7778 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.4910 - val_accuracy: 0.7656\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7656\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4685 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7778 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7778 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7778 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7812 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7795 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4677 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7812 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7795 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7812 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7812 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7812 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7812 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7812 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7830 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7830 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7812 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7830 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.7830 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7830 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4889 - val_accuracy: 0.7708\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4888 - val_accuracy: 0.7708\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7847 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7847 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7847 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7847 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7847 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7847 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7847 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7656\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7847 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4622 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4620 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7812 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4602 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7812 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7830 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7552\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4586 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4878 - val_accuracy: 0.7500\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4583 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7830 - val_loss: 0.4879 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "## Note that when we call \"fit\" again, it picks up where it left off\n",
        "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rtCek8IlIyDO",
        "outputId": "4a884465-e125-421d-bc3c-1fdcb045f83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f45a0f3f9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n = len(run_hist_1.history[\"loss\"])\n",
        "m = len(run_hist_1b.history['loss'])\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
        "\n",
        "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
        "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
        "\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQAOPs0CIyDQ"
      },
      "source": [
        "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dzf3g-_IyDQ"
      },
      "source": [
        "## Exercise 2\n",
        "For this exercise, do the following in the cells below:\n",
        "- Build a model with two hidden layers, each with 6 nodes\n",
        "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "- Use a learning rate of .003 and train for 1500 epochs\n",
        "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "- Plot the roc curve for the predictions\n",
        "\n",
        "Experiment with different learning rates, numbers of epochs, and network structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TxHpmlPHIyDS",
        "outputId": "d0cb677e-dac2-4840-ece3-e3424d24ce47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 14ms/step - loss: 0.6721 - accuracy: 0.6215 - val_loss: 0.6677 - val_accuracy: 0.6667\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.6441 - val_loss: 0.6645 - val_accuracy: 0.6771\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.6736 - val_loss: 0.6615 - val_accuracy: 0.6667\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.6927 - val_loss: 0.6586 - val_accuracy: 0.7031\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6597 - accuracy: 0.6962 - val_loss: 0.6560 - val_accuracy: 0.7240\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6570 - accuracy: 0.7083 - val_loss: 0.6535 - val_accuracy: 0.7188\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.7153 - val_loss: 0.6511 - val_accuracy: 0.7240\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6520 - accuracy: 0.7118 - val_loss: 0.6488 - val_accuracy: 0.7240\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.7188 - val_loss: 0.6467 - val_accuracy: 0.7083\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.7240 - val_loss: 0.6446 - val_accuracy: 0.6979\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.7188 - val_loss: 0.6426 - val_accuracy: 0.6979\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6431 - accuracy: 0.7188 - val_loss: 0.6407 - val_accuracy: 0.7188\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.7170 - val_loss: 0.6388 - val_accuracy: 0.7083\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.7205 - val_loss: 0.6371 - val_accuracy: 0.7083\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6373 - accuracy: 0.7205 - val_loss: 0.6354 - val_accuracy: 0.7135\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.7257 - val_loss: 0.6337 - val_accuracy: 0.7188\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.7257 - val_loss: 0.6321 - val_accuracy: 0.7135\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.7309 - val_loss: 0.6306 - val_accuracy: 0.7135\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.7309 - val_loss: 0.6290 - val_accuracy: 0.7031\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.7344 - val_loss: 0.6275 - val_accuracy: 0.6979\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.7344 - val_loss: 0.6261 - val_accuracy: 0.6927\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.7344 - val_loss: 0.6246 - val_accuracy: 0.6979\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6239 - accuracy: 0.7326 - val_loss: 0.6232 - val_accuracy: 0.6979\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6223 - accuracy: 0.7344 - val_loss: 0.6218 - val_accuracy: 0.7031\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.7292 - val_loss: 0.6205 - val_accuracy: 0.7031\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.7326 - val_loss: 0.6192 - val_accuracy: 0.6979\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.7326 - val_loss: 0.6178 - val_accuracy: 0.6979\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.7326 - val_loss: 0.6165 - val_accuracy: 0.6979\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.7292 - val_loss: 0.6153 - val_accuracy: 0.7083\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.7274 - val_loss: 0.6140 - val_accuracy: 0.7083\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.7292 - val_loss: 0.6128 - val_accuracy: 0.7083\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.7274 - val_loss: 0.6115 - val_accuracy: 0.7083\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.7292 - val_loss: 0.6103 - val_accuracy: 0.7083\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.7292 - val_loss: 0.6091 - val_accuracy: 0.7083\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6067 - accuracy: 0.7274 - val_loss: 0.6079 - val_accuracy: 0.7083\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6054 - accuracy: 0.7257 - val_loss: 0.6067 - val_accuracy: 0.7083\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7257 - val_loss: 0.6055 - val_accuracy: 0.7083\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.7292 - val_loss: 0.6043 - val_accuracy: 0.7135\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.7309 - val_loss: 0.6032 - val_accuracy: 0.7135\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6001 - accuracy: 0.7309 - val_loss: 0.6020 - val_accuracy: 0.7135\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7309 - val_loss: 0.6009 - val_accuracy: 0.7135\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5975 - accuracy: 0.7309 - val_loss: 0.5997 - val_accuracy: 0.7135\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.7326 - val_loss: 0.5986 - val_accuracy: 0.7135\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5950 - accuracy: 0.7326 - val_loss: 0.5975 - val_accuracy: 0.7135\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5937 - accuracy: 0.7326 - val_loss: 0.5964 - val_accuracy: 0.7188\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.7344 - val_loss: 0.5953 - val_accuracy: 0.7135\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.7378 - val_loss: 0.5942 - val_accuracy: 0.7188\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7378 - val_loss: 0.5932 - val_accuracy: 0.7188\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5888 - accuracy: 0.7378 - val_loss: 0.5921 - val_accuracy: 0.7240\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7378 - val_loss: 0.5910 - val_accuracy: 0.7240\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5864 - accuracy: 0.7361 - val_loss: 0.5900 - val_accuracy: 0.7240\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.7361 - val_loss: 0.5889 - val_accuracy: 0.7240\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.7396 - val_loss: 0.5879 - val_accuracy: 0.7240\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7413 - val_loss: 0.5868 - val_accuracy: 0.7240\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.7413 - val_loss: 0.5858 - val_accuracy: 0.7240\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5805 - accuracy: 0.7413 - val_loss: 0.5848 - val_accuracy: 0.7240\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5793 - accuracy: 0.7431 - val_loss: 0.5838 - val_accuracy: 0.7240\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7413 - val_loss: 0.5827 - val_accuracy: 0.7240\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.7413 - val_loss: 0.5817 - val_accuracy: 0.7240\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5758 - accuracy: 0.7448 - val_loss: 0.5807 - val_accuracy: 0.7240\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5747 - accuracy: 0.7448 - val_loss: 0.5797 - val_accuracy: 0.7240\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5736 - accuracy: 0.7448 - val_loss: 0.5787 - val_accuracy: 0.7292\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5725 - accuracy: 0.7465 - val_loss: 0.5777 - val_accuracy: 0.7292\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.7483 - val_loss: 0.5767 - val_accuracy: 0.7292\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7517 - val_loss: 0.5757 - val_accuracy: 0.7292\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.7535 - val_loss: 0.5748 - val_accuracy: 0.7292\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.7535 - val_loss: 0.5738 - val_accuracy: 0.7292\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7535 - val_loss: 0.5728 - val_accuracy: 0.7292\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7535 - val_loss: 0.5719 - val_accuracy: 0.7344\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7569 - val_loss: 0.5709 - val_accuracy: 0.7344\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7569 - val_loss: 0.5699 - val_accuracy: 0.7396\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5630 - accuracy: 0.7569 - val_loss: 0.5690 - val_accuracy: 0.7396\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.7569 - val_loss: 0.5680 - val_accuracy: 0.7344\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5610 - accuracy: 0.7569 - val_loss: 0.5670 - val_accuracy: 0.7396\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7569 - val_loss: 0.5661 - val_accuracy: 0.7396\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5590 - accuracy: 0.7569 - val_loss: 0.5652 - val_accuracy: 0.7396\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.7587 - val_loss: 0.5642 - val_accuracy: 0.7396\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5571 - accuracy: 0.7569 - val_loss: 0.5633 - val_accuracy: 0.7448\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7569 - val_loss: 0.5624 - val_accuracy: 0.7448\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7569 - val_loss: 0.5615 - val_accuracy: 0.7448\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7604 - val_loss: 0.5606 - val_accuracy: 0.7448\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7622 - val_loss: 0.5597 - val_accuracy: 0.7448\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7639 - val_loss: 0.5588 - val_accuracy: 0.7448\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7639 - val_loss: 0.5580 - val_accuracy: 0.7448\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5505 - accuracy: 0.7656 - val_loss: 0.5571 - val_accuracy: 0.7448\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5497 - accuracy: 0.7656 - val_loss: 0.5562 - val_accuracy: 0.7448\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7656 - val_loss: 0.5554 - val_accuracy: 0.7448\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7656 - val_loss: 0.5545 - val_accuracy: 0.7448\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5471 - accuracy: 0.7656 - val_loss: 0.5537 - val_accuracy: 0.7448\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7656 - val_loss: 0.5528 - val_accuracy: 0.7448\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.7674 - val_loss: 0.5520 - val_accuracy: 0.7448\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5445 - accuracy: 0.7674 - val_loss: 0.5512 - val_accuracy: 0.7448\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7656 - val_loss: 0.5504 - val_accuracy: 0.7448\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7674 - val_loss: 0.5496 - val_accuracy: 0.7448\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7656 - val_loss: 0.5488 - val_accuracy: 0.7448\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7656 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7656 - val_loss: 0.5473 - val_accuracy: 0.7448\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7656 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7656 - val_loss: 0.5458 - val_accuracy: 0.7448\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7674 - val_loss: 0.5450 - val_accuracy: 0.7448\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5372 - accuracy: 0.7656 - val_loss: 0.5443 - val_accuracy: 0.7448\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5365 - accuracy: 0.7674 - val_loss: 0.5435 - val_accuracy: 0.7552\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7656 - val_loss: 0.5428 - val_accuracy: 0.7552\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.7656 - val_loss: 0.5421 - val_accuracy: 0.7552\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7656 - val_loss: 0.5413 - val_accuracy: 0.7552\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5334 - accuracy: 0.7656 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7656 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5319 - accuracy: 0.7656 - val_loss: 0.5393 - val_accuracy: 0.7604\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5312 - accuracy: 0.7656 - val_loss: 0.5386 - val_accuracy: 0.7604\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7656 - val_loss: 0.5379 - val_accuracy: 0.7604\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7639 - val_loss: 0.5372 - val_accuracy: 0.7604\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7639 - val_loss: 0.5366 - val_accuracy: 0.7604\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7674 - val_loss: 0.5359 - val_accuracy: 0.7604\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5276 - accuracy: 0.7674 - val_loss: 0.5353 - val_accuracy: 0.7604\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7674 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5263 - accuracy: 0.7674 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7674 - val_loss: 0.5334 - val_accuracy: 0.7604\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7691 - val_loss: 0.5328 - val_accuracy: 0.7604\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7691 - val_loss: 0.5322 - val_accuracy: 0.7604\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5238 - accuracy: 0.7691 - val_loss: 0.5316 - val_accuracy: 0.7656\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7708 - val_loss: 0.5310 - val_accuracy: 0.7656\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7726 - val_loss: 0.5304 - val_accuracy: 0.7656\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.7726 - val_loss: 0.5298 - val_accuracy: 0.7656\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.7743 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7743 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7726 - val_loss: 0.5282 - val_accuracy: 0.7604\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7726 - val_loss: 0.5276 - val_accuracy: 0.7604\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7743 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7743 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5179 - accuracy: 0.7743 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7726 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7726 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7726 - val_loss: 0.5246 - val_accuracy: 0.7656\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7726 - val_loss: 0.5242 - val_accuracy: 0.7656\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.7726 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7743 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5143 - accuracy: 0.7726 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5139 - accuracy: 0.7743 - val_loss: 0.5224 - val_accuracy: 0.7656\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7726 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.7726 - val_loss: 0.5216 - val_accuracy: 0.7656\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7726 - val_loss: 0.5211 - val_accuracy: 0.7656\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7726 - val_loss: 0.5207 - val_accuracy: 0.7656\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7726 - val_loss: 0.5203 - val_accuracy: 0.7656\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7726 - val_loss: 0.5199 - val_accuracy: 0.7708\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7743 - val_loss: 0.5196 - val_accuracy: 0.7708\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.7743 - val_loss: 0.5192 - val_accuracy: 0.7708\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7726 - val_loss: 0.5188 - val_accuracy: 0.7708\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7726 - val_loss: 0.5184 - val_accuracy: 0.7708\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7708\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7743 - val_loss: 0.5177 - val_accuracy: 0.7708\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.7760 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.7760 - val_loss: 0.5170 - val_accuracy: 0.7708\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7760 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7760 - val_loss: 0.5163 - val_accuracy: 0.7708\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7778 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.7778 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7795 - val_loss: 0.5153 - val_accuracy: 0.7708\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7795 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7708\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7778 - val_loss: 0.5141 - val_accuracy: 0.7708\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7795 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7812 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7830 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7830 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7830 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7812 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7830 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7830 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7812 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7830 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7830 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7708\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4999 - accuracy: 0.7830 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.7830 - val_loss: 0.5100 - val_accuracy: 0.7604\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7830 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.7812 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7812 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7604\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7812 - val_loss: 0.5090 - val_accuracy: 0.7604\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4981 - accuracy: 0.7830 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7812 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7812 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7812 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7830 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.7812 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7830 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7830 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7812 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7812 - val_loss: 0.5074 - val_accuracy: 0.7604\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7830 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7812 - val_loss: 0.5071 - val_accuracy: 0.7604\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.7812 - val_loss: 0.5070 - val_accuracy: 0.7604\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7812 - val_loss: 0.5069 - val_accuracy: 0.7604\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7812 - val_loss: 0.5067 - val_accuracy: 0.7604\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7795 - val_loss: 0.5066 - val_accuracy: 0.7604\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7812 - val_loss: 0.5064 - val_accuracy: 0.7604\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7795 - val_loss: 0.5063 - val_accuracy: 0.7604\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7795 - val_loss: 0.5062 - val_accuracy: 0.7604\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7795 - val_loss: 0.5060 - val_accuracy: 0.7604\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7795 - val_loss: 0.5059 - val_accuracy: 0.7604\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7795 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7812 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.7795 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7812 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7812 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4921 - accuracy: 0.7812 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7812 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7795 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7812 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7812 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7812 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7812 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7812 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7795 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7795 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7795 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7795 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7795 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7795 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7795 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7795 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7795 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7795 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7795 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7795 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7795 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7795 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7812 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4867 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7812 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4858 - accuracy: 0.7830 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7830 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7830 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7795 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7795 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.7830 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7812 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.7830 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7830 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7812 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.7830 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7847 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7830 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7830 - val_loss: 0.5010 - val_accuracy: 0.7552\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7847 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7847 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7830 - val_loss: 0.5009 - val_accuracy: 0.7552\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7847 - val_loss: 0.5008 - val_accuracy: 0.7552\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7847 - val_loss: 0.5007 - val_accuracy: 0.7552\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7847 - val_loss: 0.5006 - val_accuracy: 0.7552\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4808 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7847 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7865 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4803 - accuracy: 0.7865 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4799 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7865 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7865 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7865 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4771 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.7882 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4763 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4762 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4761 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4760 - accuracy: 0.7865 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7899 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7899 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7899 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7899 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7882 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7882 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7899 - val_loss: 0.4995 - val_accuracy: 0.7552\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7899 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7882 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7899 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7899 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7899 - val_loss: 0.4994 - val_accuracy: 0.7552\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7899 - val_loss: 0.4993 - val_accuracy: 0.7552\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4739 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7882 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7899 - val_loss: 0.4992 - val_accuracy: 0.7552\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4734 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7899 - val_loss: 0.4991 - val_accuracy: 0.7552\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.7899 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7899 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7917 - val_loss: 0.4990 - val_accuracy: 0.7552\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4720 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4718 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7899 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7917 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4714 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4710 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7917 - val_loss: 0.4988 - val_accuracy: 0.7552\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7899 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7917 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7934 - val_loss: 0.4987 - val_accuracy: 0.7552\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7934 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7899 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7917 - val_loss: 0.4986 - val_accuracy: 0.7552\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4683 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4681 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7552\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7917 - val_loss: 0.4985 - val_accuracy: 0.7500\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7917 - val_loss: 0.4984 - val_accuracy: 0.7552\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7899 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7917 - val_loss: 0.4983 - val_accuracy: 0.7552\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7917 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7917 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7917 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7917 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7917 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7917 - val_loss: 0.4982 - val_accuracy: 0.7552\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7917 - val_loss: 0.4981 - val_accuracy: 0.7552\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7917 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4641 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7934 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7917 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.7934 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7934 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7934 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7934 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7934 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4628 - accuracy: 0.7934 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7917 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7934 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7934 - val_loss: 0.4976 - val_accuracy: 0.7552\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7934 - val_loss: 0.4976 - val_accuracy: 0.7552\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7552\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7917 - val_loss: 0.4976 - val_accuracy: 0.7552\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7934 - val_loss: 0.4976 - val_accuracy: 0.7552\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7934 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7899 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7917 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4617 - accuracy: 0.7934 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7917 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7899 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7934 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.7899 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7917 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7934 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7934 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7899 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7917 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7934 - val_loss: 0.4971 - val_accuracy: 0.7552\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7934 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7934 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7917 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7934 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7934 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7934 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7934 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7934 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7934 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7917 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.7917 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7917 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7934 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7934 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7934 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7917 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7934 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.7917 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.7934 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7934 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7934 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7934 - val_loss: 0.4967 - val_accuracy: 0.7448\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.7934 - val_loss: 0.4966 - val_accuracy: 0.7448\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7934 - val_loss: 0.4965 - val_accuracy: 0.7448\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7934 - val_loss: 0.4964 - val_accuracy: 0.7448\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7934 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7934 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7934 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7934 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7934 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7934 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7934 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.7934 - val_loss: 0.4961 - val_accuracy: 0.7448\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7934 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7934 - val_loss: 0.4960 - val_accuracy: 0.7448\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.7934 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7934 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7934 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7934 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7934 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7934 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7934 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7934 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.7917 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.7934 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7934 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7934 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7969 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7934 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4560 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7934 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7969 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7934 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.7934 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7951 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7969 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7934 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7951 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7934 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7951 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.7951 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7934 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.7969 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7969 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7969 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4551 - accuracy: 0.7951 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.7951 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.7969 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7969 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7969 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7969 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7969 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7969 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7969 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7969 - val_loss: 0.4946 - val_accuracy: 0.7500\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7969 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.7969 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7969 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7969 - val_loss: 0.4945 - val_accuracy: 0.7500\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7969 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.7951 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7969 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7969 - val_loss: 0.4944 - val_accuracy: 0.7500\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7951 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.7969 - val_loss: 0.4943 - val_accuracy: 0.7500\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7951 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7934 - val_loss: 0.4942 - val_accuracy: 0.7500\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7917 - val_loss: 0.4941 - val_accuracy: 0.7500\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7917 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.7934 - val_loss: 0.4940 - val_accuracy: 0.7500\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7917 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7951 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7934 - val_loss: 0.4939 - val_accuracy: 0.7500\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7934 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7951 - val_loss: 0.4938 - val_accuracy: 0.7500\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7951 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7951 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7934 - val_loss: 0.4937 - val_accuracy: 0.7500\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7934 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7951 - val_loss: 0.4936 - val_accuracy: 0.7500\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7951 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7934 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7917 - val_loss: 0.4935 - val_accuracy: 0.7500\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7934 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.7951 - val_loss: 0.4934 - val_accuracy: 0.7500\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7951 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7934 - val_loss: 0.4933 - val_accuracy: 0.7500\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.7934 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7951 - val_loss: 0.4932 - val_accuracy: 0.7500\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7934 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7934 - val_loss: 0.4931 - val_accuracy: 0.7500\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7934 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7951 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7951 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.7934 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7951 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7951 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7951 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7951 - val_loss: 0.4930 - val_accuracy: 0.7500\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7934 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7951 - val_loss: 0.4929 - val_accuracy: 0.7500\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.7951 - val_loss: 0.4928 - val_accuracy: 0.7500\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7951 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7951 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7951 - val_loss: 0.4927 - val_accuracy: 0.7500\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7951 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7951 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7951 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7934 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7951 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7934 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7951 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7934 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7951 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7951 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7934 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7934 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.7934 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7951 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7934 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7934 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7951 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7969 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7969 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7969 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7969 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7951 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7969 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7969 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7969 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7969 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7969 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7969 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7969 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.7969 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7951 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7969 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.7951 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7951 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7951 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7969 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7951 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7951 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7951 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7969 - val_loss: 0.4916 - val_accuracy: 0.7604\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7951 - val_loss: 0.4915 - val_accuracy: 0.7604\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.4914 - val_accuracy: 0.7604\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7951 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7969 - val_loss: 0.4913 - val_accuracy: 0.7604\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7969 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7951 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7969 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7969 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7986 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7986 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7986 - val_loss: 0.4912 - val_accuracy: 0.7604\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7969 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7986 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.7969 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.8003 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4433 - accuracy: 0.7986 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7986 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.8003 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7986 - val_loss: 0.4911 - val_accuracy: 0.7604\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.8003 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.8003 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8003 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.8003 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8003 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8003 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.8003 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.8021 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.8003 - val_loss: 0.4910 - val_accuracy: 0.7604\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4425 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7969 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.7969 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.7969 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.8003 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7986 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.7986 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.8003 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7986 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8021 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8003 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.8003 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.7986 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.8003 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.8003 - val_loss: 0.4908 - val_accuracy: 0.7656\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.8003 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7986 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8003 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7986 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8003 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7986 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7986 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8003 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.4907 - val_accuracy: 0.7656\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7986 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8021 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8003 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8003 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7986 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8003 - val_loss: 0.4906 - val_accuracy: 0.7656\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8038 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7656\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.8038 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.8038 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.8038 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.8038 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7656\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.8038 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.8038 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.8038 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8038 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8038 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4382 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4379 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4378 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4377 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7656\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4372 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8021 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4357 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8021 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4352 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.8003 - val_loss: 0.4902 - val_accuracy: 0.7656\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.8021 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8003 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4343 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4342 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4341 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4340 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4332 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8021 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4329 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7969 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.8021 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.8003 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7969 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8003 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7969 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7986 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7951 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.7934 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7969 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.4901 - val_accuracy: 0.7656\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7951 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.7951 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7969 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7969 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7969 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.4899 - val_accuracy: 0.7656\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7969 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7969 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4274 - accuracy: 0.7969 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4273 - accuracy: 0.7969 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7969 - val_loss: 0.4898 - val_accuracy: 0.7656\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7951 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7969 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7951 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7969 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7951 - val_loss: 0.4897 - val_accuracy: 0.7656\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4268 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4266 - accuracy: 0.7934 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7656\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7656\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7934 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.7934 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7934 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7934 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7969 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7934 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4253 - accuracy: 0.7986 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7969 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7951 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.7986 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4247 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7969 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4243 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.7969 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4242 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4239 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7986 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4234 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4209 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4203 - accuracy: 0.8003 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4198 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4190 - accuracy: 0.7986 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7986 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4188 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.7951 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.7969 - val_loss: 0.4893 - val_accuracy: 0.7708\n"
          ]
        }
      ],
      "source": [
        "### BEGIN SOLUTION\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
        "model_2.add(Dense(6,  activation=\"relu\"))\n",
        "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VBOoQoglIyDU",
        "outputId": "bd40f73d-24bf-48d4-9a0d-e5eafc5bcd42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "run_hist_2.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7uos3aIKIyDV",
        "outputId": "e1e33ba3-938e-4084-e9b1-02f2dbec0fd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Accuracy over iterations')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n = len(run_hist_2.history[\"loss\"])\n",
        "\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
        "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "ax.set_title('Loss over iterations')\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
        "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
        "ax.legend(loc='lower right')\n",
        "ax.set_title('Accuracy over iterations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "T3hAsHKkIyDX",
        "outputId": "b6dc9936-bba9-49a4-b7e9-e8be093bb389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "accuracy is 0.641\n",
            "roc-auc is 0.832\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# y_pred_class_nn_2 = model_2.predict_classes(X_test_norm) > Sequential.predict_classes() depricated\n",
        "y_pred_class_nn_2 = np.argmax(model_2.predict(X_test_norm),axis=1)\n",
        "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
        "print('')\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
        "### END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD9-l72fIyDl"
      },
      "source": [
        "---\n",
        "### Machine Learning Foundation (C) 2020 IBM Corporation"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "05d_LAB_Keras_Intro.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}